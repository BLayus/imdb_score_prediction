# -*- coding: utf-8 -*-
"""IMDB_Score_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rJ4uw1HyAhM28_bhqvvXUJ4Xp5NTAyXS

## Bibliotecas e Dataset
"""

!pip install --upgrade scikit-learn

# Import libraries
import pandas as pd
import numpy as np
import re
from datetime import datetime
import datetime as dt

# Data viz libraries
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import plotly.express as px

# Satistical Libraries
from scipy import stats
import scipy.stats
from scipy.stats import chi2_contingency
from scipy.stats import norm

# Machine Learning Libraries
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, TargetEncoder
from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler
from sklearn.preprocessing import FunctionTransformer

from sklearn.pipeline import Pipeline
from sklearn.pipeline import make_pipeline
from sklearn.compose import make_column_transformer

from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score, RandomizedSearchCV
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, mean_absolute_percentage_error

from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso

from sklearn.inspection import permutation_importance



import warnings
warnings.filterwarnings("ignore")

# Import dataset from github

df = pd.read_csv('https://raw.githubusercontent.com/BLayus/imdb_score_prediction/main/dataset/Dataset_imdb.csv', index_col= 'Unnamed: 0', encoding= 'utf_8')

# Dataset sample

df.sample(5)

# Info

df.info()

# Display null values with a heatmap figure

sns.heatmap(df.isnull(), cbar=False)

df.IMDB_Rating.value_counts()

"""##Cleaning and Preparing the Data"""

# The 'Apollo 13' movie has no date, in official website, I found that release year was 1995
# Using Loc to find and replace the value

df.loc[df['Released_Year'] == 'PG', 'Released_Year'] = 1995

# Convert Released_Year to datetime year only

df['Released_Year']= pd.to_datetime(df['Released_Year'], format= '%Y', errors= 'coerce').dt.year

# Converting strings in column "Runtime" to int 64 and removing substring 'min'

df['Runtime']= df['Runtime'].str.extract('(\d+)', expand=False).astype('int64')

# Replace commas in Gross strings

df['Gross']= df['Gross'].str.replace(r'[^\w\s]', '', regex= True)

# Converting gross type to numerical and fill NaN

df['Gross']= df['Gross'].fillna(0).astype('int64')

# Imputing missing values

# Certificate column, imput with mode

imputer= SimpleImputer(missing_values= np.nan, strategy= 'most_frequent')

data= df[['Certificate']]

imputer= imputer.fit(data)
df['Certificate']= imputer.transform(data).flatten()

print(df['Certificate'].isnull().sum())

# Meta Score column, imput with median

imputer= SimpleImputer(missing_values= np.nan, strategy= 'median')

data= df[['Meta_score']]

imputer= imputer.fit(data)
df['Meta_score']= imputer.transform(data).flatten()

print(df['Meta_score'].isnull().sum())

# Certificate grouping and converting to numerical info
# As this grouping has low cardinality, we can use One Hot Encoder

def certificate_groups(col):
  if col in ['U', 'G', 'Passed', 'Approved', np.nan]:
    return 'all_age_group'
  elif col in ['PG', 'TV-PG', 'U/A', 'GP']:
    return 'accompanied_group'
  elif col in ['PG-13', 'TV-14']:
    return '14_years_group'
  elif col in ['16', 'R']:
    return '16_years_group'
  else:
    return 'adult_group'

df['Certificate']= df['Certificate'].apply(certificate_groups)

# Import scrapped data from scrapping notebook

from google.colab import drive
drive.mount('/content/drive')

df_scrapping= pd.read_csv('/content/drive/MyDrive/Data Science/Case Lighthouse Indicium/scrapping.csv')

df_scrapping

# Merge scrapped data into df
# Use '.loc' to align data properly based on matching 'Series_Title' values

for index, row in df_scrapping.iterrows():
    df.loc[df['Series_Title'] == row['Series_Title'], 'Gross'] = row['Gross']

df.info()

"""## Exploratory Data Analysis

###Análise Univariada
"""

# Applying a plot style to the charts

#plt.style.use('seaborn-v0_8')

sns.set_style('darkgrid', {'grid.color': '.8',
                           'grid.linestyle': '-',
                           'text.color': '.2',
                           'xtick.color': 'dimgray',
                           'ytick.color': 'dimgray',
                           'axes.labelcolor': 'dimgray'})

# Defining a color pallete

colors = ['#4c94de', 'grey', 'cornflowerblue', 'silver', 'lightsteelblue', 'whitesmoke']
sns.set_palette(sns.color_palette(colors))

# Analysing "Released_Year" feature

release_date = df.groupby('Released_Year').size().reset_index(name= 'Quantidade')
pd.DataFrame(release_date).sort_values(by= ['Quantidade'], ascending= False)

plt.figure(figsize=(15,5))
plt.title('Quantidade de Lançamentos')
plt.xlabel('Ano')
plt.ylabel('Quantidade')
plt.xticks(rotation= 90, fontsize= 7)

sns.barplot(x= 'Released_Year', y= 'Quantidade', data= release_date)

plt.show()

# Analysing certificates, which means a classification of the movie in U => Uncensored,
# UA=> Uncensored with a parental advisory, A => Adult

''' From IMDB website:
G - For all audiences
PG - Parental Guidance Suggested (mainly for under 10's)
PG-13 - Parental Guidance Suggested for children under 13
R - Under 17 not admitted without parent or guardian
NC-17 - Under 17 not admitted
Approved - Pre-1968 titles only (from the MPA site) Under the Hays Code, films were simply approved or disapproved based on whether they were deemed 'moral' or 'immoral'.)
'''

certificates = df.groupby('Certificate').size().reset_index(name= 'Quantidade')
pd.DataFrame(certificates).sort_values(by= ['Quantidade'], ascending= False)

plt.figure(figsize=(10,5))
plt.title('Quantidade de Filmes por Classificação Etária')
plt.xlabel('Classificação')
plt.ylabel('Quantidade')
plt.xticks(rotation= 0, fontsize= 7)

sns.barplot(x= 'Certificate', y= 'Quantidade', data= certificates)

plt.show()

# Exploring distribution of movies lenght

plt.figure(figsize=(10,5))
plt.title('Distribuição da Duração dos Filmes')
plt.xlabel('Duração (Min)')
plt.ylabel('Quantidade')
plt.xticks(rotation= 0, fontsize= 7)

sns.histplot(data= df, x= 'Runtime', kde= True )

plt.show()

# Analysing count of genres

genres = df.Genre.value_counts().head(20)

# There is 202 categories of genres, we can look just at the 20 bigger categories

plt.figure(figsize=(10,5))
plt.title('Gêneros Principais')
plt.xlabel('Gêneros')
plt.ylabel('Quantidade')
plt.xticks(rotation= 90, fontsize= 7)

sns.barplot(data= genres )

plt.show()

# Plot the distribution of rating

plt.figure(figsize= (10, 5))
plt.title('Distribuição de Ratings')
plt.xlabel('Rating')
plt.ylabel('Quantidade')
plt.xticks(rotation= 0, fontsize= 7)

sns.histplot(data= df, x= 'IMDB_Rating', kde= True)

plt.show()

# Plot the distribution of Meta_score

plt.figure(figsize= (10, 5))
plt.title('Distribuição de Meta Score')
plt.xlabel('Meta Score')
plt.ylabel('Quantidade')
plt.xticks(rotation= 0, fontsize= 7)

sns.histplot(data= df, x= 'Meta_score', kde= True)

plt.show()

# Analysing most frequent Directors

director= df.groupby('Director').size().reset_index(name= 'Quantidade')
director= pd.DataFrame(director).sort_values(by= ['Quantidade'], ascending= False).head(10)

plt.figure(figsize= (10, 5))

plt.title(f'Frequência de Diretores')
plt.xlabel('Diretores')
plt.ylabel('Quantidade')
plt.xticks(rotation= 90, fontsize= 7)

sns.barplot(x= 'Director', y= 'Quantidade', data= director)

plt.show()

# For star 1 to 4, lets plot the names that frequently appears

cols = ['Star1', 'Star2', 'Star3', 'Star4']

fig, axes = plt.subplots(2, 2, figsize= (15, 12))
fig.suptitle('Atores que Aparecem Com Mais Frequência')
fig.subplots_adjust(wspace= 0.25, hspace= 0.6)

for i, col in enumerate(cols):
  row= i // 2
  col_idx= i % 2
  ax= axes[row, col_idx]

  groups= df.groupby(col).size().reset_index(name= 'Quantidade')
  groups= pd.DataFrame(groups).sort_values(by= ['Quantidade'], ascending= False).head(10)

  sns.barplot(x= col, y= 'Quantidade', data= groups, ax= ax)

  ax.set_title(f'Frequência de {col}')
  ax.set_xlabel(f'{col}', labelpad= 20)
  ax.set_ylabel('Quantidade')
  ticks= ax.get_xticks()
  labels = ax.get_xticklabels()
  ax.set_xticks(ticks, labels, rotation= 90, fontsize= 7)


plt.show()

# Analysing distribution of Number of Votes

plt.figure(figsize= (10, 5))
plt.title('Distribuição de Number of Votes')
plt.xlabel('Number of Votes')
plt.ylabel('Quantidade')
plt.xticks(rotation= 0, fontsize= 7)

sns.histplot(data= df, x= 'No_of_Votes', kde= True)

plt.show()

# Analysing distribution of Gross

# As gross values varies a lot, I will create bins to better understand classes of gross revenue
# Binning values to better understand distribution, using pd.qcut, to discretize into percentiles

bins= (0, 500000, 1000000, 5000000, 25000000, 50000000, 100000000, 500000000, 1000000000)

df['Gross_Bin']= pd.cut(df.Gross, bins= bins, right= True)

plt.figure(figsize= (10, 5))
plt.title('Distribuição dos Filmes por Faixa de Faturamento')
plt.xlabel('Faturamento Bruto')
plt.ylabel('Quantidade')
plt.xticks(rotation= 0, fontsize= 8)

ax= sns.countplot(data= df, x= 'Gross_Bin')

xlabels = ['{:.2f}M'.format(float(x.get_text().replace('(', '').replace(']', '').split(',')[0])/1e6) for x in ax.get_xticklabels()]
ax.set_xticklabels(xlabels)

plt.show()

# Removing NaN from bin categories

df['Gross_Bin'].fillna(df['Gross_Bin'].cat.categories[0], inplace=True)

"""####Análise do Faturamento Médio"""

# Movies with highest gross revenue

movies_revenue= df.groupby('Series_Title')['Gross'].mean().reset_index(name= 'Gross').sort_values('Gross', ascending= False).head(10)

plt.figure(figsize= (10, 6))
ax= sns.barplot(data= movies_revenue, x= 'Gross', y= 'Series_Title', color= colors[1])

plt.title('Filmes com Maior Faturamento')
plt.xlabel('Faturamento')
plt.ylabel('Filme')
plt.xticks(rotation= 0, fontsize= 7)

xlabels= ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'M'))

ax.bar_label(ax.containers[0], labels=[f'{x/1000000:,.0f}M' for x in ax.containers[0].datavalues], fontsize=7, color='firebrick', padding=3)

plt.show()

# Directors with the highest average gross revenue

directors_revenue= df.groupby('Director')['Gross'].mean().reset_index(name= 'Faturamento').sort_values('Faturamento', ascending= False).head(10)

plt.figure(figsize= (10, 6))
ax= sns.barplot(data= directors_revenue, x= 'Faturamento', y= 'Director')

plt.title('Diretores Com Maior Faturamento Médio')
plt.xlabel('Faturamento')
plt.ylabel('Diretor')
plt.xticks(rotation= 0, fontsize= 7)

xlabels= ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'M'))
ax.bar_label(ax.containers[0], labels=[f'{x/1000000:,.0f}M' for x in ax.containers[0].datavalues], fontsize=7, color='firebrick', padding=3)

plt.show()

# Protagonists with the highest average gross revenue

stars_revenue= df.groupby('Star1')['Gross'].mean().reset_index(name= 'Faturamento').sort_values('Faturamento', ascending= False).head(10)

plt.figure(figsize= (10, 6))
ax= sns.barplot(data= stars_revenue, x= 'Faturamento', y= 'Star1')

plt.title('Protagonistas Com Maior Faturamento Médio')
plt.xlabel('Faturamento')
plt.ylabel('Atores')
plt.xticks(rotation= 0, fontsize= 7)

xlabels= ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'M'))
ax.bar_label(ax.containers[0], labels=[f'{x/1000000:,.0f}M' for x in ax.containers[0].datavalues], fontsize=7, color='firebrick', padding=3)

plt.show()

"""####Análise do IMDB Rating"""

# What are the most rated movies in this dataset?

most_rated= df.groupby('Series_Title')['IMDB_Rating'].mean().reset_index(name= 'IMDB_Rating').sort_values('IMDB_Rating', ascending= False).head(10)

plt.figure(figsize= (10, 6))
ax= sns.barplot(data= most_rated, x= 'IMDB_Rating', y= 'Series_Title', color= colors[1])

plt.title('Filmes com Maior IMDB Rating')
plt.xlabel('IMDB Rating')
plt.ylabel('Filme')
plt.xticks(rotation= 0, fontsize= 7)
ax.bar_label(ax.containers[0], fontsize= 7, color= 'firebrick', padding= 3)

plt.show()

# Which directors produced movies with the highest ratings in this dataset?

director_rated= df.groupby('Director')['IMDB_Rating'].mean().reset_index(name= 'IMDB_Rating').sort_values('IMDB_Rating', ascending= False).head(10)

plt.figure(figsize= (10, 6))
ax= sns.barplot(data= director_rated, x= 'IMDB_Rating', y= 'Director')

plt.title('Diretores Que Produziram Filmes Com Maior IMDB Rating')
plt.xlabel('IMDB Rating')
plt.ylabel('Diretor')
plt.xticks(rotation= 0, fontsize= 7)
ax.bar_label(ax.containers[0], fontsize= 7, color= 'firebrick', padding= 3)

plt.show()

# Which actors played in the movies with the highest ratings in this dataset?

actors_rated= df.groupby('Star1')['IMDB_Rating'].mean().reset_index(name= 'IMDB_Rating').sort_values('IMDB_Rating', ascending= False).head(10)

plt.figure(figsize= (10, 6))
ax= sns.barplot(data= actors_rated, x= 'IMDB_Rating', y= 'Star1')

plt.title('Atores Que Atuaram nos Filmes Com Maior IMDB Rating')
plt.xlabel('IMDB Rating')
plt.ylabel('Atores')
plt.xticks(rotation= 0, fontsize= 7)
ax.bar_label(ax.containers[0], fontsize= 7, color= 'firebrick', padding= 3)

plt.show()

"""####Análise do Meta Score, Pontuação da Crítica Especializazda"""

# Movies with highest Meta Score

movies_score= df.groupby('Series_Title')['Meta_score'].mean().reset_index(name= 'Meta_score').sort_values('Meta_score', ascending= False).head(10)

plt.figure(figsize= (10, 6))
ax= sns.barplot(data= movies_score, x= 'Meta_score', y= 'Series_Title', color= colors[1])

plt.title('Filmes com Maior Meta Score')
plt.xlabel('Meta Score')
plt.ylabel('Filme')
plt.xticks(rotation= 0, fontsize= 7)

xlabels= ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'M'))
ax.bar_label(ax.containers[0], fontsize=7, color='firebrick', padding=3)

plt.show()

# Which directors produced movies with the highest Meta Scores in this dataset?

director_score= df.groupby('Director')['Meta_score'].mean().reset_index(name= 'Meta_score').sort_values('Meta_score', ascending= False).head(10)

plt.figure(figsize= (10, 6))
ax= sns.barplot(data= director_score, x= 'Meta_score', y= 'Director')

plt.title('Diretores Que Produziram Filmes Com Maior Meta Score')
plt.xlabel('Meta Score')
plt.ylabel('Diretor')
plt.xticks(rotation= 0, fontsize= 7)
ax.bar_label(ax.containers[0], fontsize= 7, color= 'firebrick', padding= 3)

plt.show()

# Which actors played in the movies with the highest ratings in this dataset?

actors_score= df.groupby('Star1')['Meta_score'].mean().reset_index(name= 'Meta_score').sort_values('Meta_score', ascending= False).head(10)

plt.figure(figsize= (10, 6))
ax= sns.barplot(data= actors_score, x= 'Meta_score', y= 'Star1')

plt.title('Atores Que Atuaram nos Filmes Com Maior Meta Score')
plt.xlabel('Meta Score')
plt.ylabel('Atores')
plt.xticks(rotation= 0, fontsize= 7)
ax.bar_label(ax.containers[0], fontsize= 7, color= 'firebrick', padding= 3)

plt.show()

"""###Análise Multivariada"""

# Defining a function to plot charts with variables related to gross revenue

def Chart_Revenue(df, col_1, col_2):

  df_var = df.groupby(col_1)[col_2].sum().reset_index(name= 'Faturamento_Total').sort_values('Faturamento_Total', ascending= False).head(10)

  plt.figure(figsize= (10, 6))
  plt.title(f'Soma de Faturamento por {col_1}')
  plt.xlabel(col_1)
  plt.ylabel('Soma de Faturamento')
  plt.xticks(rotation= 90, fontsize= 7)

  ax= sns.barplot(data= df_var, x= col_1, y= 'Faturamento_Total')

  ylabels= ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000000) + 'M'))

  plt.show()

# Plot relationship between Certificate and Gross

Chart_Revenue(df, 'Certificate', 'Gross')

# Plot relationship between Genre and Gross

Chart_Revenue(df, 'Genre', 'Gross')

# Plot relationship between IMDB_Rating and Gross

Chart_Revenue(df, 'IMDB_Rating', 'Gross')

# Plot relationship between Meta_score and Gross

Chart_Revenue(df, 'Meta_score', 'Gross')

# Plot relationship between Director and Gross
# Wich directors and actors leads to a greater revenue?

Chart_Revenue(df, 'Director', 'Gross')

# Plot relationship between Star1 and Gross
# Wich actors leads to a greater revenue?

Chart_Revenue(df, 'Star1', 'Gross')

# Plot relationship between Star1 and Gross
# Wich second actors leads to a greater revenue?

Chart_Revenue(df, 'Star2', 'Gross')

"""###Análise de Correlações"""

# Separating categorical and numerical features

num_cols= ['Released_Year', 'Runtime', 'IMDB_Rating', 'Meta_score', 'No_of_Votes', 'Gross']

cat_cols= ['Series_Title', 'Certificate', 'Genre', 'Overview', 'Director', 'Star1', 'Star2', 'Star3', 'Star4']

# Analysing correlation between numerical variables

correlation = df.corr(method= 'pearson', numeric_only= True)

plt.figure(figsize= (12, 6))
sns.heatmap(correlation, annot= True, cmap= 'YlOrBr', fmt= '.2f')
plt.title('Matriz de Correlação')

plt.show()

"""####**Observações sobre a Matriz de Correlações**

  * Há uma correlação de 0.25 entre o ano de lançamento e o faturamento dos filmes. Esse aumento de faturamento pode ser explicado por audiências maiores dos filmes mais recentes, tanto por motivos de aumento de população, quanto por um maior alcance da distribuição dos filmes em mais países do mundo.

  * Há uma correlação forte de 0.62 entre o faturamento e o número de votos de um filme. À medida em que os filmes são assistidos por um público maior, o faturamento bruto se torna maior e a quantidade de pessoas que votam no site do IMDB favoráveis a este filme também fica maior.

  * Ao contrário do que se possa haver imaginado, o Rating do IMDB e o Meta Score (nota atribuída pela crítica especializada ao filme) de 0.08 e -0.05, respectivamente, não são correlacionados com o faturamento dos filmes.
"""

# Analysing correlations between categorical variables using chi-square tests to determine if there is a statistical significance

# H0 => Null hypothesis => the two columns are not correlated
# H1 => Alternative hypothesis => there is no correlation between the columns

# Deining a function to execute the Chi2 Test

def chi2_test(df, col_index, col_compare):
  cross_tab= pd.crosstab(index= df[col_index], columns= df[col_compare])

  chi_test= chi2_contingency(cross_tab)
  p, x= chi_test[1], 'reject' if chi_test [1] < 0.05 else 'accept'

  print(f"The p-value for {col_index} is {chi_test[1]} therefore we {x} the null Hypothesis with {chi_test[2]} degrees of freedom")

# Testing all categorical columns with Gross_Bin column

for i in cat_cols:
  chi2_test(df, i, 'Gross_Bin')

"""####**Análise de Correlação Entre Colunas Categóricas**

  * Há uma relação estatisticamente significativa entre as faixas de faturamento total e as variáveis 'Certificate', 'Genre', 'Director' e 'Star1'.

  Isso significa que filmes com faturamento maior estão provavelmente relacionados a estas variáveis, tornando-as boas variáveis preditoras.
  
  * Para as demais variáveis o teste Chi2 aceita a hipótese nula, ou seja, não há uma relação estatisticamente significativa entre as variáveis 'Title, 'Overview', 'Star2', 'Star3' e 'Star4' e um  maior ou menor faturamento.

###Analisando a Feature Overview Usando NLP
"""

